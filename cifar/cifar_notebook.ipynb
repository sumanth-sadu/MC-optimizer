{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iFL5IDJAkm6",
        "outputId": "7c75ac10-6cda-4b3c-943d-0f135612fbfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=> Building model...\n",
            "Enter model number : 1.Vgg16 2.ResNet18 3.ResNet50 4.SENet18 5.ResNeXt29 6.DenseNet121 7.GoogleNet : 1\n",
            "Enter optimizer : 1.Adabelief 2.RAdam 3.Adam 4.Adam_GC: 1\n",
            "=> no checkpoint found at '/content/drive/MyDrive/pytorch-cifar-models/checkpoints/cifar100_vgg16_radam_bat128_graph/checkpoint.pth'\n",
            "=> loading cifar100 data...\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "/content/drive/MyDrive/pytorch-cifar-models/optimizers/AdaBelief.py:153: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)\n",
            "  grad.add_(group['weight_decay'], p.data)\n",
            "Epoch: [0][0/391]\tTime 2.518 (2.518)\tData 0.194 (0.194)\tLoss 4.8702 (4.8702)\tPrec 0.781% (0.781%)\n",
            "Epoch: [0][10/391]\tTime 0.119 (0.335)\tData 0.002 (0.020)\tLoss 4.6505 (4.8533)\tPrec 2.344% (1.420%)\n",
            "Epoch: [0][20/391]\tTime 0.119 (0.233)\tData 0.002 (0.011)\tLoss 4.6156 (4.7589)\tPrec 1.562% (1.451%)\n",
            "Epoch: [0][30/391]\tTime 0.105 (0.196)\tData 0.002 (0.008)\tLoss 4.5090 (4.7070)\tPrec 2.344% (1.588%)\n",
            "Epoch: [0][40/391]\tTime 0.118 (0.178)\tData 0.003 (0.007)\tLoss 4.5605 (4.6704)\tPrec 3.125% (1.562%)\n",
            "Epoch: [0][50/391]\tTime 0.119 (0.166)\tData 0.002 (0.006)\tLoss 4.6868 (4.6575)\tPrec 0.781% (1.532%)\n",
            "Epoch: [0][60/391]\tTime 0.118 (0.159)\tData 0.002 (0.005)\tLoss 4.5298 (4.6446)\tPrec 2.344% (1.562%)\n",
            "Epoch: [0][70/391]\tTime 0.122 (0.153)\tData 0.002 (0.005)\tLoss 4.7425 (4.6455)\tPrec 0.000% (1.496%)\n",
            "Epoch: [0][80/391]\tTime 0.120 (0.149)\tData 0.002 (0.005)\tLoss 4.6484 (4.6414)\tPrec 0.000% (1.485%)\n",
            "Epoch: [0][90/391]\tTime 0.124 (0.146)\tData 0.003 (0.004)\tLoss 4.5489 (4.6287)\tPrec 1.562% (1.614%)\n",
            "Epoch: [0][100/391]\tTime 0.119 (0.143)\tData 0.003 (0.004)\tLoss 4.5396 (4.6213)\tPrec 1.562% (1.570%)\n",
            "Epoch: [0][110/391]\tTime 0.121 (0.141)\tData 0.003 (0.004)\tLoss 4.6101 (4.6150)\tPrec 1.562% (1.562%)\n",
            "Epoch: [0][120/391]\tTime 0.121 (0.140)\tData 0.003 (0.004)\tLoss 4.4943 (4.6091)\tPrec 3.906% (1.653%)\n",
            "Epoch: [0][130/391]\tTime 0.122 (0.138)\tData 0.002 (0.004)\tLoss 4.5769 (4.6022)\tPrec 0.000% (1.682%)\n",
            "Epoch: [0][140/391]\tTime 0.122 (0.137)\tData 0.002 (0.004)\tLoss 4.5070 (4.5951)\tPrec 2.344% (1.734%)\n",
            "Epoch: [0][150/391]\tTime 0.121 (0.136)\tData 0.004 (0.004)\tLoss 4.4903 (4.5861)\tPrec 0.781% (1.744%)\n",
            "Epoch: [0][160/391]\tTime 0.123 (0.135)\tData 0.002 (0.004)\tLoss 4.4565 (4.5802)\tPrec 1.562% (1.771%)\n",
            "Epoch: [0][170/391]\tTime 0.120 (0.134)\tData 0.002 (0.004)\tLoss 4.3787 (4.5733)\tPrec 2.344% (1.800%)\n",
            "Epoch: [0][180/391]\tTime 0.120 (0.133)\tData 0.002 (0.004)\tLoss 4.4852 (4.5666)\tPrec 1.562% (1.809%)\n",
            "Epoch: [0][190/391]\tTime 0.121 (0.132)\tData 0.003 (0.004)\tLoss 4.4029 (4.5615)\tPrec 3.125% (1.832%)\n",
            "Epoch: [0][200/391]\tTime 0.120 (0.132)\tData 0.002 (0.004)\tLoss 4.4741 (4.5553)\tPrec 4.688% (1.858%)\n",
            "Epoch: [0][210/391]\tTime 0.116 (0.131)\tData 0.003 (0.003)\tLoss 4.4376 (4.5502)\tPrec 0.000% (1.851%)\n",
            "Epoch: [0][220/391]\tTime 0.124 (0.131)\tData 0.002 (0.003)\tLoss 4.3994 (4.5434)\tPrec 3.125% (1.870%)\n",
            "Epoch: [0][230/391]\tTime 0.131 (0.130)\tData 0.003 (0.003)\tLoss 4.4777 (4.5376)\tPrec 4.688% (1.938%)\n",
            "Epoch: [0][240/391]\tTime 0.122 (0.130)\tData 0.002 (0.003)\tLoss 4.5207 (4.5314)\tPrec 3.125% (1.968%)\n",
            "Epoch: [0][250/391]\tTime 0.122 (0.130)\tData 0.002 (0.003)\tLoss 4.4334 (4.5251)\tPrec 3.125% (1.992%)\n",
            "Epoch: [0][260/391]\tTime 0.131 (0.129)\tData 0.005 (0.003)\tLoss 4.4475 (4.5192)\tPrec 2.344% (2.017%)\n",
            "Epoch: [0][270/391]\tTime 0.111 (0.129)\tData 0.002 (0.003)\tLoss 4.3220 (4.5119)\tPrec 3.906% (2.050%)\n",
            "Epoch: [0][280/391]\tTime 0.104 (0.129)\tData 0.003 (0.003)\tLoss 4.5781 (4.5057)\tPrec 3.906% (2.071%)\n",
            "Epoch: [0][290/391]\tTime 0.121 (0.129)\tData 0.002 (0.003)\tLoss 4.2646 (4.4995)\tPrec 1.562% (2.083%)\n",
            "Epoch: [0][300/391]\tTime 0.122 (0.128)\tData 0.003 (0.003)\tLoss 4.2138 (4.4924)\tPrec 3.906% (2.105%)\n",
            "Epoch: [0][310/391]\tTime 0.120 (0.128)\tData 0.002 (0.003)\tLoss 4.4208 (4.4882)\tPrec 3.125% (2.148%)\n",
            "Epoch: [0][320/391]\tTime 0.131 (0.128)\tData 0.002 (0.003)\tLoss 4.3063 (4.4820)\tPrec 2.344% (2.176%)\n",
            "Epoch: [0][330/391]\tTime 0.119 (0.128)\tData 0.005 (0.003)\tLoss 4.0836 (4.4755)\tPrec 3.906% (2.204%)\n",
            "Epoch: [0][340/391]\tTime 0.121 (0.127)\tData 0.002 (0.003)\tLoss 4.3101 (4.4695)\tPrec 0.000% (2.206%)\n",
            "Epoch: [0][350/391]\tTime 0.126 (0.127)\tData 0.002 (0.003)\tLoss 4.2876 (4.4633)\tPrec 3.125% (2.239%)\n",
            "Epoch: [0][360/391]\tTime 0.122 (0.127)\tData 0.004 (0.003)\tLoss 4.2435 (4.4573)\tPrec 3.125% (2.270%)\n",
            "Epoch: [0][370/391]\tTime 0.116 (0.127)\tData 0.002 (0.003)\tLoss 4.2281 (4.4511)\tPrec 1.562% (2.293%)\n",
            "Epoch: [0][380/391]\tTime 0.123 (0.127)\tData 0.003 (0.003)\tLoss 4.5368 (4.4480)\tPrec 2.344% (2.286%)\n",
            "Epoch: [0][390/391]\tTime 1.524 (0.130)\tData 0.002 (0.003)\tLoss 4.1956 (4.4441)\tPrec 2.500% (2.300%)\n",
            "train_function\n",
            "4.444147259521484\n",
            "Test: [0/100]\tTime 0.663 (0.663)\tLoss 4.2075 (4.2075)\tPrec 7.000% (7.000%)\n",
            "Test: [10/100]\tTime 0.037 (0.097)\tLoss 4.2352 (4.2852)\tPrec 4.000% (3.000%)\n",
            "Test: [20/100]\tTime 0.045 (0.069)\tLoss 4.1436 (4.2818)\tPrec 5.000% (2.762%)\n",
            "Test: [30/100]\tTime 0.042 (0.061)\tLoss 4.2541 (4.2801)\tPrec 4.000% (2.774%)\n",
            "Test: [40/100]\tTime 0.042 (0.055)\tLoss 4.3454 (4.2819)\tPrec 7.000% (3.098%)\n",
            "Test: [50/100]\tTime 0.035 (0.052)\tLoss 4.1932 (4.2841)\tPrec 7.000% (3.137%)\n",
            "Test: [60/100]\tTime 0.036 (0.049)\tLoss 4.2113 (4.2854)\tPrec 3.000% (3.115%)\n",
            "Test: [70/100]\tTime 0.042 (0.048)\tLoss 4.2426 (4.2867)\tPrec 5.000% (3.169%)\n",
            "Test: [80/100]\tTime 0.040 (0.047)\tLoss 4.4296 (4.2849)\tPrec 1.000% (3.099%)\n",
            "Test: [90/100]\tTime 0.040 (0.046)\tLoss 4.1424 (4.2807)\tPrec 3.000% (3.165%)\n",
            "val_function\n",
            "4.279725360870361\n",
            " * Prec 3.170% \n",
            "Saving model ===> \n",
            "/content/drive/MyDrive/pytorch-cifar-models/checkpoints/cifar100_vgg16_radam_bat128_graph/checkpoint.pth/checkpoint.pth\n",
            "\n",
            "Epoch: [1][0/391]\tTime 0.331 (0.331)\tData 0.197 (0.197)\tLoss 4.2285 (4.2285)\tPrec 1.562% (1.562%)\n",
            "Epoch: [1][10/391]\tTime 0.126 (0.140)\tData 0.002 (0.021)\tLoss 4.2988 (4.2689)\tPrec 2.344% (2.841%)\n",
            "Epoch: [1][20/391]\tTime 0.120 (0.132)\tData 0.002 (0.012)\tLoss 4.2972 (4.2641)\tPrec 2.344% (2.976%)\n",
            "Epoch: [1][30/391]\tTime 0.118 (0.128)\tData 0.002 (0.009)\tLoss 4.2694 (4.2633)\tPrec 1.562% (2.823%)\n",
            "Epoch: [1][40/391]\tTime 0.120 (0.127)\tData 0.002 (0.007)\tLoss 4.2544 (4.2517)\tPrec 1.562% (2.915%)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/pytorch-cifar-models/main.py\", line 331, in <module>\n",
            "    main()\n",
            "  File \"/content/drive/MyDrive/pytorch-cifar-models/main.py\", line 178, in main\n",
            "    train(trainloader, model, criterion, optimizer, epoch)\n",
            "  File \"/content/drive/MyDrive/pytorch-cifar-models/main.py\", line 235, in train\n",
            "    losses.update(loss.item(), input.size(0))\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!python \"/content/drive/MyDrive/pytorch-cifar-models/main.py\" --cifar-type 100 --resume --epochs 100 --batch-size 128 --lr 0.001 --start \"/content/drive/MyDrive/pytorch-cifar-models/checkpoints/cifar100_vgg16_radam_bat128/checkpoint.pth\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cifar_notebook",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
